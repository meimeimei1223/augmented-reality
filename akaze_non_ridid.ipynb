{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4abc6f24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import math\n",
    "from PIL import Image\n",
    "import statistics\n",
    "import collections\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from IPython.display import Image, display\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4200d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    \"\"\"ndarray 配列をインラインで Notebook 上に表示する。\n",
    "    \"\"\"\n",
    "    ret, encoded = cv2.imencode(\".jpg\", img)\n",
    "    display(Image(encoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82c9f378",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (384, 216)\n",
    "# １枚目の画像を読み込む\n",
    "img1 = cv2.imread(\"image1.jpg\")\n",
    "# ２枚目の画像を読み込む\n",
    "img2 = cv2.imread(\"image2.jpg\") \n",
    "img1 = cv2.resize(img1, IMG_SIZE)\n",
    "img2 = cv2.resize(img2, IMG_SIZE)\n",
    "#imshow(img1)\n",
    "#imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a82a767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affin 変換用のフォルダ作成\n",
    "new_dir_path = \"./AffinImages\"\n",
    "os.mkdir(new_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0fb9319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Affin 変換\n",
    "af_x = 0\n",
    "af_y = 0\n",
    "m = np.float32([[1, af_x, 0], [af_y, 1, 0]])\n",
    "im = img2\n",
    "h, w, ch = img2.shape\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "cv2.imwrite(\"AffinImages/0.jpg\",img2_affin)\n",
    "\n",
    "af_x = 0.1\n",
    "af_y = 0\n",
    "m = np.float32([[1, af_x, -10], [af_y, 1, 0]])\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "cv2.imwrite(\"AffinImages/x1.jpg\",img2_affin)\n",
    "\n",
    "\n",
    "af_x = 0.2\n",
    "af_y = 0\n",
    "m = np.float32([[1, af_x, -20], [af_y, 1, 0]])\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "cv2.imwrite(\"AffinImages/x2.jpg\",img2_affin)\n",
    "\n",
    "af_x = 0.3\n",
    "af_y = 0\n",
    "m = np.float32([[1, af_x, -30], [af_y, 1, 0]])\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "cv2.imwrite(\"AffinImages/x3.jpg\",img2_affin)\n",
    "\n",
    "af_x = 0.4\n",
    "af_y = 0\n",
    "m = np.float32([[1, af_x, -40], [af_y, 1, 0]])\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "cv2.imwrite(\"AffinImages/x4.jpg\",img2_affin)\n",
    "\n",
    "\n",
    "af_x = -0.1\n",
    "af_y = 0\n",
    "m = np.float32([[1, af_x, 10], [af_y, 1, 0]])\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "cv2.imwrite(\"AffinImages/x-1.jpg\",img2_affin)\n",
    "\n",
    "af_x = -0.2\n",
    "af_y = 0\n",
    "m = np.float32([[1, af_x, 20], [af_y, 1, 0]])\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "cv2.imwrite(\"AffinImages/x-2.jpg\",img2_affin)\n",
    "\n",
    "af_x = -0.3\n",
    "af_y = 0\n",
    "m = np.float32([[1, af_x, 30], [af_y, 1, 0]])\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "#cv2.imwrite(\"Affin/x-3.jpg\",img2_affin)\n",
    "\n",
    "af_x = -0.4\n",
    "af_y = 0\n",
    "m = np.float32([[1, af_x, 40], [af_y, 1, 0]])\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "cv2.imwrite(\"AffinImages/x-4.jpg\",im)\n",
    "\n",
    "af_x = 0\n",
    "af_y = 0.1\n",
    "m = np.float32([[1, af_x, 0], [af_y, 1, -25]])\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "cv2.imwrite(\"AffinImages/y1.jpg\",img2_affin)\n",
    "\n",
    "af_x =  0\n",
    "af_y = 0.2\n",
    "m = np.float32([[1, af_x, 0], [af_y, 1, -50]])\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "cv2.imwrite(\"AffinImages/y2.jpg\",img2_affin)\n",
    "\n",
    "\n",
    "af_x =  0\n",
    "af_y =  0.3\n",
    "m = np.float32([[1, af_x, 0], [af_y, 1, -75]])\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "cv2.imwrite(\"AffinImages/y3.jpg\",img2_affin)\n",
    "\n",
    "\n",
    "af_x =  0\n",
    "af_y = -0.1\n",
    "m = np.float32([[1, af_x, 0], [af_y, 1, 25]])\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "cv2.imwrite(\"AffinImages/y-1.jpg\",img2_affin)\n",
    "\n",
    "af_x =  0\n",
    "af_y = -0.2\n",
    "m = np.float32([[1, af_x, 0], [af_y, 1, 50]])\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "cv2.imwrite(\"AffinImages/y-2.jpg\",img2_affin)\n",
    "\n",
    "\n",
    "af_x =  0\n",
    "af_y = -0.3\n",
    "m = np.float32([[1, af_x, 0], [af_y, 1, 75]])\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "cv2.imwrite(\"AffinImages/y-3.jpg\",img2_affin)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e047872",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIR =  \"./AffinImages/\"\n",
    "files = os.listdir(IMG_DIR)\n",
    "mylistfig = []\n",
    "mylistret = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d82298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BFMatcherオブジェクトの生成\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "detector = cv2.AKAZE_create()\n",
    "(target_kp, target_des) = detector.detectAndCompute(img1, None)\n",
    "extraceted_img = cv2.drawKeypoints(img1, target_kp, None, flags=4)\n",
    "#imshow(extraceted_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a547f7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    comparing_img_path = IMG_DIR + file\n",
    "    comparing_img = cv2.imread(comparing_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    comparing_img = cv2.resize(comparing_img, IMG_SIZE)\n",
    "    (comparing_kp, comparing_des) = detector.detectAndCompute(comparing_img, None)\n",
    "    #result = cv2.matchTemplate(target_img, comparing_img, cv2.TM_CCORR_NORMED)\n",
    "    matches = bf.match(target_des, comparing_des)\n",
    "    dist = [m.distance for m in matches]\n",
    "    ret = sum(dist) / len(dist)\n",
    "    #print(file, ret)\n",
    "    mylistfig.append(file)\n",
    "    mylistret.append(ret)\n",
    "    #template.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5482ecc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117.77272727272727, 'y-2.jpg', './AffinImages/y-2.jpg')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = mylistret.index(min(mylistret))\n",
    "min(mylistret)\n",
    "mylistfig[n]\n",
    "result_img_path = IMG_DIR + mylistfig[n]\n",
    "min(mylistret),mylistfig[n], result_img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46dffb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# マッチした画像を読み込む\n",
    "img2 = cv2.imread(result_img_path) \n",
    "img1 = cv2.resize(img1, IMG_SIZE)\n",
    "img2 = cv2.resize(img2, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8c14fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contours(img):\n",
    "    # HSV 色空間に変換する。\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # 2値化する。\n",
    "    bin_img = cv2.inRange(hsv, (0, 0, 0), (255, 200, 255))\n",
    "\n",
    "    # 輪郭を滑らかにする。\n",
    "    bin_img = cv2.medianBlur(bin_img, 5)\n",
    "    #imshow(bin_img)\n",
    "\n",
    "    # 輪郭を抽出する。\n",
    "    contours, hierarchy = cv2.findContours(\n",
    "        bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "\n",
    "    # 面積が小さい輪郭は除去する。\n",
    "    contours = list(filter(lambda x: cv2.contourArea(x) > 100, contours))\n",
    "\n",
    "    # 輪郭抽出の結果を描画する。\n",
    "    dst = cv2.drawContours(img.copy(), contours, -1, color=(0, 0, 255), thickness=2)\n",
    "    #imshow(dst)\n",
    "\n",
    "    return contours\n",
    "\n",
    "train_contours = get_contours(img1)\n",
    "query_contours = get_contours(img2)\n",
    "\n",
    "train_obj = {\"contour\": train_contours[0]}\n",
    "query_obj = {\"contour\": query_contours[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7c8901f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.309932708740234\n",
      "11.768289566040039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[138, 162],\n",
       "       [159,  62],\n",
       "       [281,  88],\n",
       "       [260, 188]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_rect(contour):\n",
    "    # 輪郭の外接矩形を取得する。\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    # 輪郭のモーメントを計算する。\n",
    "    M = cv2.moments(contour)\n",
    "    # モーメントから重心を計算する。\n",
    "    cx = M[\"m10\"] / M[\"m00\"]\n",
    "    cy = M[\"m01\"] / M[\"m00\"]\n",
    "\n",
    "    return {\"tl\": (x, y), \"br\": (x + w, y + h), \"center\": (cx, cy)}\n",
    "\n",
    "\n",
    "def to_int_tuple(pt):\n",
    "    return tuple(int(x) for x in pt)\n",
    "\n",
    "\n",
    "train_obj.update(get_rect(train_obj[\"contour\"]))\n",
    "query_obj.update(get_rect(query_obj[\"contour\"]))\n",
    "dst1 = img1.copy()\n",
    "dst2 = img2.copy()\n",
    "cv2.rectangle(dst1, train_obj[\"tl\"], train_obj[\"br\"], color=(0, 0, 255), thickness=2)\n",
    "cv2.circle(dst1, to_int_tuple(train_obj[\"center\"]), 5, color=(0, 0, 255), thickness=-1)\n",
    "cv2.rectangle(dst2, query_obj[\"tl\"], query_obj[\"br\"], color=(0, 0, 255), thickness=2)\n",
    "cv2.circle(dst2, to_int_tuple(query_obj[\"center\"]), 5, color=(0, 0, 255), thickness=-1)\n",
    "img1_cropped = img1[train_obj[\"tl\"][1]:train_obj[\"br\"][1], train_obj[\"tl\"][0]:train_obj[\"br\"][0], :]\n",
    "img2_cropped = img2[query_obj[\"tl\"][1]:query_obj[\"br\"][1], query_obj[\"tl\"][0]:query_obj[\"br\"][0], :]\n",
    "IMG_SIZE2 = ( train_obj[\"br\"][0] - train_obj[\"tl\"][0],  train_obj[\"br\"][1] - train_obj[\"tl\"][1])\n",
    "img2_resized = cv2.resize(img2_cropped, IMG_SIZE2)\n",
    "#imshow(dst1)\n",
    "#imshow(dst2)\n",
    "#imshow(img1_cropped)\n",
    "#imshow(img2_resized)\n",
    "\n",
    "\n",
    "rect1 = cv2.minAreaRect(train_contours[0])\n",
    "box1 = cv2.boxPoints(rect1)\n",
    "box1 = np.int0(box1)\n",
    "img1_angle = cv2.drawContours(img1,[box1],0,(0,0,255),2)\n",
    "#plt.imshow(img1_angle)\n",
    "print(rect1[2])\n",
    "rect1\n",
    "box1\n",
    "\n",
    "rect2 = cv2.minAreaRect(query_contours[0])\n",
    "box2 = cv2.boxPoints(rect2)\n",
    "box2 = np.int0(box2)\n",
    "img2_angle = cv2.drawContours(img2,[box2],0,(0,0,255),2)\n",
    "#plt.imshow(img2_angle)\n",
    "print(rect2[2])\n",
    "#rect2\n",
    "box2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcef8f48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = np.float32([[1, 0, train_obj[\"tl\"][0]], [0, 1, train_obj[\"tl\"][1]]])\n",
    "im = img2_resized\n",
    "h, w, ch = img1.shape\n",
    "im_trasformed = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "#plt.imshow(im_trasformed)\n",
    "#検出結果を描画した画像を出力する\n",
    "cv2.imwrite(\"im_trasformed.jpg\",im_trasformed)\n",
    "#M = cv2.getRotationMatrix2D(center= train_obj[\"center\"], angle=250, scale=1)\n",
    "#dst = cv2.warpAffine(im_trasformed, M, dsize=(w, h))\n",
    "#imshow(dst)\n",
    "#img = cv2.addWeighted(img1, 0.5, dst, 0.1, 0)\n",
    "#imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57856d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.309932708740234\n",
      "82.23483276367188\n"
     ]
    }
   ],
   "source": [
    "threshold=100\n",
    "fname = \"./im_trasformed.jpg\"\n",
    "img_color= cv2.imread(fname) \n",
    "img_gray = cv2.imread(fname,cv2.IMREAD_GRAYSCALE) \n",
    "img_blur = cv2.blur(img_gray,(9,9)) \n",
    "# オブジェクトimg_blurを閾値threshold(220)で反転二値化しimg_binaryに代入\n",
    "ret, img_binary= cv2.threshold(img_blur, threshold, 255, cv2.THRESH_BINARY_INV) \n",
    "# img_binaryを輪郭抽出\n",
    "contours, hierarchy = cv2.findContours(img_binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) \n",
    "rect2 = cv2.minAreaRect(contours[0])\n",
    "box2 = cv2.boxPoints(rect2)\n",
    "box2 = np.int0(box2)\n",
    "img2_trans_angle = cv2.drawContours(img_color,[box2],0,(0,0,255),2)\n",
    "#imshow(img2_trans_angle)\n",
    "\n",
    "rect1 = cv2.minAreaRect(train_contours[0])\n",
    "box1 = cv2.boxPoints(rect1)\n",
    "box1 = np.int0(box1)\n",
    "img1_angle = cv2.drawContours(img1,[box1],0,(0,0,255),2)\n",
    "#imshow(img1_angle)\n",
    "print(rect1[2])\n",
    "print(rect2[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71e00673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-19.07509994506836"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angle =  -((90- rect2[2]) + rect1[2])\n",
    "angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0814108d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = cv2.getRotationMatrix2D(center= train_obj[\"center\"], angle=angle, scale=1)\n",
    "im_trasformed2 = cv2.warpAffine(im_trasformed, M, dsize=(w, h), borderValue=(0, 225, 0))\n",
    "#imshow(im_trasformed2)\n",
    "cv2.imwrite(\"im_trasformed2.jpg\",im_trasformed2)\n",
    "img = cv2.addWeighted(img1, 0.5, im_trasformed2, 0.5, 0)\n",
    "cv2.imwrite(\"im_augmented.jpg\",img)\n",
    "#imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b452b83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron",
   "language": "python",
   "name": "detectron"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
