{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4abc6f24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import math\n",
    "from PIL import Image\n",
    "import statistics\n",
    "import collections\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from IPython.display import Image, display\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4200d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    \"\"\"ndarray 配列をインラインで Notebook 上に表示する。\n",
    "    \"\"\"\n",
    "    ret, encoded = cv2.imencode(\".jpg\", img)\n",
    "    display(Image(encoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82c9f378",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (384, 216)\n",
    "# １枚目の画像を読み込む\n",
    "img1 = cv2.imread(\"image1.jpg\")\n",
    "# ２枚目の画像を読み込む\n",
    "img2 = cv2.imread(\"image2.jpg\") \n",
    "img1 = cv2.resize(img1, IMG_SIZE)\n",
    "img2 = cv2.resize(img2, IMG_SIZE)\n",
    "#imshow(img1)\n",
    "#imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a82a767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affin 変換用のフォルダ作成\n",
    "new_dir_path = \"./AffinImages\"\n",
    "os.mkdir(new_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0fb9319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Affin 変換\n",
    "af_x = 0\n",
    "af_y = 0\n",
    "m = np.float32([[1, af_x, 0], [af_y, 1, 0]])\n",
    "im = img2\n",
    "h, w, ch = img2.shape\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "cv2.imwrite(\"AffinImages/0.jpg\",img2_affin)\n",
    "\n",
    "af_x = 0.1\n",
    "af_y = 0\n",
    "m = np.float32([[1, af_x, -10], [af_y, 1, 0]])\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "cv2.imwrite(\"AffinImages/x1.jpg\",img2_affin)\n",
    "\n",
    "\n",
    "af_x = 0.2\n",
    "af_y = 0\n",
    "m = np.float32([[1, af_x, -20], [af_y, 1, 0]])\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "cv2.imwrite(\"AffinImages/x2.jpg\",img2_affin)\n",
    "\n",
    "af_x = 0.3\n",
    "af_y = 0\n",
    "m = np.float32([[1, af_x, -30], [af_y, 1, 0]])\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "cv2.imwrite(\"AffinImages/x3.jpg\",img2_affin)\n",
    "\n",
    "af_x = 0.4\n",
    "af_y = 0\n",
    "m = np.float32([[1, af_x, -40], [af_y, 1, 0]])\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "cv2.imwrite(\"AffinImages/x4.jpg\",img2_affin)\n",
    "\n",
    "\n",
    "af_x = -0.1\n",
    "af_y = 0\n",
    "m = np.float32([[1, af_x, 10], [af_y, 1, 0]])\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "cv2.imwrite(\"AffinImages/x-1.jpg\",img2_affin)\n",
    "\n",
    "af_x = -0.2\n",
    "af_y = 0\n",
    "m = np.float32([[1, af_x, 20], [af_y, 1, 0]])\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "cv2.imwrite(\"AffinImages/x-2.jpg\",img2_affin)\n",
    "\n",
    "af_x = -0.3\n",
    "af_y = 0\n",
    "m = np.float32([[1, af_x, 30], [af_y, 1, 0]])\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "#cv2.imwrite(\"Affin/x-3.jpg\",img2_affin)\n",
    "\n",
    "af_x = -0.4\n",
    "af_y = 0\n",
    "m = np.float32([[1, af_x, 40], [af_y, 1, 0]])\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "cv2.imwrite(\"AffinImages/x-4.jpg\",im)\n",
    "\n",
    "af_x = 0\n",
    "af_y = 0.1\n",
    "m = np.float32([[1, af_x, 0], [af_y, 1, -25]])\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "cv2.imwrite(\"AffinImages/y1.jpg\",img2_affin)\n",
    "\n",
    "af_x =  0\n",
    "af_y = 0.2\n",
    "m = np.float32([[1, af_x, 0], [af_y, 1, -50]])\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "cv2.imwrite(\"AffinImages/y2.jpg\",img2_affin)\n",
    "\n",
    "\n",
    "af_x =  0\n",
    "af_y =  0.3\n",
    "m = np.float32([[1, af_x, 0], [af_y, 1, -75]])\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "cv2.imwrite(\"AffinImages/y3.jpg\",img2_affin)\n",
    "\n",
    "\n",
    "af_x =  0\n",
    "af_y = -0.1\n",
    "m = np.float32([[1, af_x, 0], [af_y, 1, 25]])\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "cv2.imwrite(\"AffinImages/y-1.jpg\",img2_affin)\n",
    "\n",
    "af_x =  0\n",
    "af_y = -0.2\n",
    "m = np.float32([[1, af_x, 0], [af_y, 1, 50]])\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "cv2.imwrite(\"AffinImages/y-2.jpg\",img2_affin)\n",
    "\n",
    "\n",
    "af_x =  0\n",
    "af_y = -0.3\n",
    "m = np.float32([[1, af_x, 0], [af_y, 1, 75]])\n",
    "img2_affin = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "cv2.imwrite(\"AffinImages/y-3.jpg\",img2_affin)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e047872",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIR =  \"./AffinImages/\"\n",
    "files = os.listdir(IMG_DIR)\n",
    "mylistfig = []\n",
    "mylistret = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d82298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BFMatcherオブジェクトの生成\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "detector = cv2.AKAZE_create()\n",
    "(target_kp, target_des) = detector.detectAndCompute(img1, None)\n",
    "extraceted_img = cv2.drawKeypoints(img1, target_kp, None, flags=4)\n",
    "#imshow(extraceted_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a547f7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    comparing_img_path = IMG_DIR + file\n",
    "    comparing_img = cv2.imread(comparing_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    comparing_img = cv2.resize(comparing_img, IMG_SIZE)\n",
    "    (comparing_kp, comparing_des) = detector.detectAndCompute(comparing_img, None)\n",
    "    #result = cv2.matchTemplate(target_img, comparing_img, cv2.TM_CCORR_NORMED)\n",
    "    matches = bf.match(target_des, comparing_des)\n",
    "    dist = [m.distance for m in matches]\n",
    "    ret = sum(dist) / len(dist)\n",
    "    #print(file, ret)\n",
    "    mylistfig.append(file)\n",
    "    mylistret.append(ret)\n",
    "    #template.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5482ecc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117.77272727272727, 'y-2.jpg', './AffinImages/y-2.jpg')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = mylistret.index(min(mylistret))\n",
    "min(mylistret)\n",
    "mylistfig[n]\n",
    "result_img_path = IMG_DIR + mylistfig[n]\n",
    "min(mylistret),mylistfig[n], result_img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46dffb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# マッチした画像を読み込む\n",
    "img2 = cv2.imread(result_img_path) \n",
    "img1 = cv2.resize(img1, IMG_SIZE)\n",
    "img2 = cv2.resize(img2, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8c14fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contours(img):\n",
    "    # HSV 色空間に変換する。\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # 2値化する。\n",
    "    bin_img = cv2.inRange(hsv, (0, 0, 0), (255, 200, 255))\n",
    "\n",
    "    # 輪郭を滑らかにする。\n",
    "    bin_img = cv2.medianBlur(bin_img, 5)\n",
    "    #imshow(bin_img)\n",
    "\n",
    "    # 輪郭を抽出する。\n",
    "    contours, hierarchy = cv2.findContours(\n",
    "        bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "\n",
    "    # 面積が小さい輪郭は除去する。\n",
    "    contours = list(filter(lambda x: cv2.contourArea(x) > 100, contours))\n",
    "\n",
    "    # 輪郭抽出の結果を描画する。\n",
    "    dst = cv2.drawContours(img.copy(), contours, -1, color=(0, 0, 255), thickness=2)\n",
    "    #imshow(dst)\n",
    "\n",
    "    return contours\n",
    "\n",
    "train_contours = get_contours(img1)\n",
    "query_contours = get_contours(img2)\n",
    "\n",
    "train_obj = {\"contour\": train_contours[0]}\n",
    "query_obj = {\"contour\": query_contours[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7c8901f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.309932708740234\n",
      "11.768289566040039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[138, 162],\n",
       "       [159,  62],\n",
       "       [281,  88],\n",
       "       [260, 188]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_rect(contour):\n",
    "    # 輪郭の外接矩形を取得する。\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    # 輪郭のモーメントを計算する。\n",
    "    M = cv2.moments(contour)\n",
    "    # モーメントから重心を計算する。\n",
    "    cx = M[\"m10\"] / M[\"m00\"]\n",
    "    cy = M[\"m01\"] / M[\"m00\"]\n",
    "\n",
    "    return {\"tl\": (x, y), \"br\": (x + w, y + h), \"center\": (cx, cy)}\n",
    "\n",
    "\n",
    "def to_int_tuple(pt):\n",
    "    return tuple(int(x) for x in pt)\n",
    "\n",
    "\n",
    "train_obj.update(get_rect(train_obj[\"contour\"]))\n",
    "query_obj.update(get_rect(query_obj[\"contour\"]))\n",
    "dst1 = img1.copy()\n",
    "dst2 = img2.copy()\n",
    "cv2.rectangle(dst1, train_obj[\"tl\"], train_obj[\"br\"], color=(0, 0, 255), thickness=2)\n",
    "cv2.circle(dst1, to_int_tuple(train_obj[\"center\"]), 5, color=(0, 0, 255), thickness=-1)\n",
    "cv2.rectangle(dst2, query_obj[\"tl\"], query_obj[\"br\"], color=(0, 0, 255), thickness=2)\n",
    "cv2.circle(dst2, to_int_tuple(query_obj[\"center\"]), 5, color=(0, 0, 255), thickness=-1)\n",
    "img1_cropped = img1[train_obj[\"tl\"][1]:train_obj[\"br\"][1], train_obj[\"tl\"][0]:train_obj[\"br\"][0], :]\n",
    "img2_cropped = img2[query_obj[\"tl\"][1]:query_obj[\"br\"][1], query_obj[\"tl\"][0]:query_obj[\"br\"][0], :]\n",
    "IMG_SIZE2 = ( train_obj[\"br\"][0] - train_obj[\"tl\"][0],  train_obj[\"br\"][1] - train_obj[\"tl\"][1])\n",
    "img2_resized = cv2.resize(img2_cropped, IMG_SIZE2)\n",
    "#imshow(dst1)\n",
    "#imshow(dst2)\n",
    "#imshow(img1_cropped)\n",
    "#imshow(img2_resized)\n",
    "\n",
    "\n",
    "rect1 = cv2.minAreaRect(train_contours[0])\n",
    "box1 = cv2.boxPoints(rect1)\n",
    "box1 = np.int0(box1)\n",
    "img1_angle = cv2.drawContours(img1,[box1],0,(0,0,255),2)\n",
    "#plt.imshow(img1_angle)\n",
    "print(rect1[2])\n",
    "rect1\n",
    "box1\n",
    "\n",
    "rect2 = cv2.minAreaRect(query_contours[0])\n",
    "box2 = cv2.boxPoints(rect2)\n",
    "box2 = np.int0(box2)\n",
    "img2_angle = cv2.drawContours(img2,[box2],0,(0,0,255),2)\n",
    "#plt.imshow(img2_angle)\n",
    "print(rect2[2])\n",
    "#rect2\n",
    "box2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcef8f48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = np.float32([[1, 0, train_obj[\"tl\"][0]], [0, 1, train_obj[\"tl\"][1]]])\n",
    "im = img2_resized\n",
    "h, w, ch = img1.shape\n",
    "im_trasformed = cv2.warpAffine(im, m, (w, h), borderValue=(0, 225, 0))\n",
    "#plt.imshow(im_trasformed)\n",
    "#検出結果を描画した画像を出力する\n",
    "cv2.imwrite(\"im_trasformed.jpg\",im_trasformed)\n",
    "#M = cv2.getRotationMatrix2D(center= train_obj[\"center\"], angle=250, scale=1)\n",
    "#dst = cv2.warpAffine(im_trasformed, M, dsize=(w, h))\n",
    "#imshow(dst)\n",
    "#img = cv2.addWeighted(img1, 0.5, dst, 0.1, 0)\n",
    "#imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57856d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.309932708740234\n",
      "82.23483276367188\n"
     ]
    }
   ],
   "source": [
    "threshold=100\n",
    "fname = \"./im_trasformed.jpg\"\n",
    "img_color= cv2.imread(fname) \n",
    "img_gray = cv2.imread(fname,cv2.IMREAD_GRAYSCALE) \n",
    "img_blur = cv2.blur(img_gray,(9,9)) \n",
    "# オブジェクトimg_blurを閾値threshold(220)で反転二値化しimg_binaryに代入\n",
    "ret, img_binary= cv2.threshold(img_blur, threshold, 255, cv2.THRESH_BINARY_INV) \n",
    "# img_binaryを輪郭抽出\n",
    "contours, hierarchy = cv2.findContours(img_binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) \n",
    "rect2 = cv2.minAreaRect(contours[0])\n",
    "box2 = cv2.boxPoints(rect2)\n",
    "box2 = np.int0(box2)\n",
    "img2_trans_angle = cv2.drawContours(img_color,[box2],0,(0,0,255),2)\n",
    "#imshow(img2_trans_angle)\n",
    "\n",
    "rect1 = cv2.minAreaRect(train_contours[0])\n",
    "box1 = cv2.boxPoints(rect1)\n",
    "box1 = np.int0(box1)\n",
    "img1_angle = cv2.drawContours(img1,[box1],0,(0,0,255),2)\n",
    "#imshow(img1_angle)\n",
    "print(rect1[2])\n",
    "print(rect2[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71e00673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-19.07509994506836"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angle =  -((90- rect2[2]) + rect1[2])\n",
    "angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0814108d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = cv2.getRotationMatrix2D(center= train_obj[\"center\"], angle=angle, scale=1)\n",
    "im_trasformed2 = cv2.warpAffine(im_trasformed, M, dsize=(w, h), borderValue=(0, 225, 0))\n",
    "#imshow(im_trasformed2)\n",
    "cv2.imwrite(\"im_trasformed2.jpg\",im_trasformed2)\n",
    "img = cv2.addWeighted(img1, 0.5, im_trasformed2, 0.5, 0)\n",
    "cv2.imwrite(\"im_augmented.jpg\",img)\n",
    "#imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b452b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64790b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd71559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a612d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9a1774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4976dbf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d787d3d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbc134e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bd7c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe33471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b95845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2977ad6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033d7667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2bdea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b4fb4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96d56d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2bdd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "float_img = cv.imread(\"./im_trasformed.jpg\", cv.IMREAD_GRAYSCALE)\n",
    "ref_img = cv.imread('C:/Users/a00m0/OneDrive/Nishimask/images1/image.jpg', cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "akaze = cv.AKAZE_create()\n",
    "float_kp, float_des = akaze.detectAndCompute(float_img, None)\n",
    "ref_kp, ref_des = akaze.detectAndCompute(ref_img, None)\n",
    "\n",
    "bf = cv.BFMatcher()\n",
    "matches = bf.knnMatch(float_des, ref_des, k=2)\n",
    "\n",
    "plt.imshow(float_img)\n",
    "plt.imshow(ref_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6897d413",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_matches = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.95 * n.distance:\n",
    "        good_matches.append([m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb5a2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 適切なキーポイントを選択\n",
    "ref_matched_kpts = np.float32(\n",
    "    [float_kp[m[0].queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "sensed_matched_kpts = np.float32(\n",
    "    [ref_kp[m[0].trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91219ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ホモグラフィを計算\n",
    "H, status = cv.findHomography(\n",
    "    ref_matched_kpts, sensed_matched_kpts, cv.RANSAC, 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d418b06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像を変換\n",
    "warped_image = cv.warpPerspective(\n",
    "    float_img, H, (float_img.shape[1], float_img.shape[0]))\n",
    "\n",
    "plt.imshow(warped_image)\n",
    "cv.imwrite('warped.jpg', warped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5225bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_MATCH_COUNT = 10\n",
    "img1 = cv.imread(\"./im_trasformed.jpg\", cv.IMREAD_GRAYSCALE)\n",
    "img2 = cv.imread('C:/Users/a00m0/OneDrive/Nishimask/images1/image.jpg', cv.IMREAD_GRAYSCALE)\n",
    "# Initiate SIFT detector\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks = 50)\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "matches = flann.knnMatch(des1,des2,k=2)\n",
    "# store all the good matches as per Lowe's ratio test.\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 1 *n.distance:\n",
    "        good.append(m)\n",
    "len(good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9114ead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)   \n",
    "M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "matchesMask = mask.ravel().tolist() \n",
    "h,w = img1.shape\n",
    "pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "dst = cv2.perspectiveTransform(pts,M)\n",
    "img2 = cv2.polylines(img2,[np.int32(dst)],True,255,3, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b66f2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8fd5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "                   singlePointColor = None,\n",
    "                   matchesMask = matchesMask, # draw only inliers\n",
    "                   flags = 2)\n",
    "img3 = cv2.drawMatches(img1,kp1,img2,kp2,good,None,**draw_params)\n",
    "plt.imshow(img3, 'gray'),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d8834f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe04461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a354c591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9ce0b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e25ba30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43253f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e306f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8635ca18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18b2264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4775c385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9db855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AKAZE検出器の生成\n",
    "akaze = cv2.AKAZE_create() \n",
    "# gray1にAKAZEを適用、特徴点を検出\n",
    "kp1, des1 = akaze.detectAndCompute(gray1,None) \n",
    "# gray2にAKAZEを適用、特徴点を検出\n",
    "kp2, des2 = akaze.detectAndCompute(gray2,None) \n",
    "\n",
    "# BFMatcherオブジェクトの生成\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "# Match descriptorsを生成\n",
    "matches = bf.match(des1, des2)\n",
    "\n",
    "# matchesをdescriptorsの似ている順にソートする \n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "# 検出結果を描画する\n",
    "img3 = cv2.drawMatches(img1, kp1, img2, kp2, matches[:10], None, flags = cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "#検出結果を描画した画像を出力する\n",
    "cv2.imwrite(\"result8.png\",img3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba097a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##cv2.imshow(\"result.png\",img3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc5057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contours(img):\n",
    "    # HSV 色空間に変換する。\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # 2値化する。\n",
    "    bin_img = cv2.inRange(hsv, (0, 0, 0), (255, 200, 255))\n",
    "\n",
    "    # 輪郭を滑らかにする。\n",
    "    bin_img = cv2.medianBlur(bin_img, 5)\n",
    "    imshow(bin_img)\n",
    "\n",
    "    # 輪郭を抽出する。\n",
    "    contours, hierarchy = cv2.findContours(\n",
    "        bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "\n",
    "    # 面積が小さい輪郭は除去する。\n",
    "    contours = list(filter(lambda x: cv2.contourArea(x) > 100, contours))\n",
    "\n",
    "    # 輪郭抽出の結果を描画する。\n",
    "    dst = cv2.drawContours(img.copy(), contours, -1, color=(0, 0, 255), thickness=2)\n",
    "    imshow(dst)\n",
    "\n",
    "    return contours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf8e00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像を読み込む。\n",
    "train_img = cv2.imread(target_img_path)  # 探したい物体\n",
    "query_img = cv2.imread(result_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ecc3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輪郭を抽出する。\n",
    "train_contours = get_contours(train_img)\n",
    "query_contours = get_contours(query_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a44f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検出結果を格納するオブジェクト\n",
    "train_obj = {\"contour\": train_contours[0]}\n",
    "query_objs = [{\"contour\": x} for x in query_contours]\n",
    "\n",
    "# 各物体のマスクを作成する。\n",
    "for obj in query_objs:\n",
    "    # 輪郭内部を255、それ以外を0としたマスク画像を作成する。\n",
    "    mask = np.zeros(train_img.shape[:2], dtype=np.uint8)\n",
    "    cv2.drawContours(mask, [obj[\"contour\"]], -1, color=255, thickness=-1)\n",
    "    imshow(mask)\n",
    "\n",
    "    obj[\"mask\"] = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc287fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1df1c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBR 特徴量検出器を作成する。\n",
    "#detector = cv2.ORB_create()\n",
    "detector = cv2.AKAZE_create()\n",
    "# 探したい物体の特徴点及び特徴量記述子を計算する。\n",
    "train_kp, train_desc = detector.detectAndCompute(train_img, None)\n",
    "\n",
    "# 検出対象の画像の物体の特徴点及び特徴量記述子を計算する。\n",
    "for obj in query_objs:\n",
    "    obj[\"kp\"], obj[\"desc\"] = detector.detectAndCompute(query_img, obj[\"mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fdebe5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# マッチング器を作成する。\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "\n",
    "for obj in query_objs:\n",
    "    # 特徴点マッチングを行う。\n",
    "    matches = bf.knnMatch(obj[\"desc\"], train_desc, k=2)\n",
    "\n",
    "    # レシオテストを行う。\n",
    "    good_matches = []\n",
    "    for first, second in matches:\n",
    "        if first.distance < second.distance * 0.9:\n",
    "            good_matches.append(first)\n",
    "\n",
    "    # マッチング結果を描画する。\n",
    "    dst = cv2.drawMatches(query_img, obj[\"kp\"], train_img, train_kp, good_matches, None)\n",
    "    imshow(dst)\n",
    "\n",
    "    if len(good_matches) > 100:\n",
    "        # 十分な数のマッチングが存在する場合、同一物体と判定する。\n",
    "        obj[\"is_target\"] = True\n",
    "\n",
    "        # マッチした特徴点を格納する。\n",
    "        obj[\"match_query_kp\"] = np.array(\n",
    "            [obj[\"kp\"][x.queryIdx].pt for x in good_matches]\n",
    "        )\n",
    "        obj[\"match_train_kp\"] = np.array(\n",
    "            [train_kp[x.trainIdx].pt for x in good_matches]\n",
    "        )\n",
    "    else:\n",
    "        obj[\"is_target\"] = False\n",
    "\n",
    "# 検出できた物体だけ残す\n",
    "query_objs = [x for x in query_objs if x[\"is_target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6ba6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pose(query_kp, train_kp):\n",
    "    query_kp = np.reshape(query_kp, (-1, 1, 2))\n",
    "    train_kp = np.reshape(train_kp, (-1, 1, 2))\n",
    "\n",
    "    # ホモグラフィー行列を求める。\n",
    "    A, inliers = cv2.estimateAffinePartial2D(train_kp, query_kp)\n",
    "\n",
    "    # 行列から平行移動量を求める。\n",
    "    M = A[:2, :2]\n",
    "    t = A[:, 2]\n",
    "    # 行列から回転角度を求める。\n",
    "    degree = np.rad2deg(-np.arctan2(A[0, 1], A[0, 0]))\n",
    "\n",
    "    return {\"angle\": degree, \"M\": M, \"t\": t}\n",
    "\n",
    "\n",
    "for obj in query_objs:\n",
    "    obj.update(calc_pose(obj[\"match_query_kp\"], obj[\"match_train_kp\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b9970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.addWeighted(train_img, 0.5, query_img, 0.5, 0)\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5b656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d225fc56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1056626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平行移動及び回転角度を描画する。\n",
    "img = cv2.addWeighted(train_img, 0.5, query_img, 0.5, 0)\n",
    "\n",
    "for obj in query_objs:\n",
    "    src = np.array(train_obj[\"center\"])\n",
    "\n",
    "    # 移動前の点に推定したアフィン変換 M x + b を適用する。\n",
    "    dst = obj[\"M\"] @ src + obj[\"t\"]\n",
    "\n",
    "    # アフィン変換後の点及び回転量を描画して、合っていることを確かめる。\n",
    "\n",
    "    # アフィン変換後の点を描画する。\n",
    "    cv2.arrowedLine(\n",
    "        img, to_int_tuple(src), to_int_tuple(dst), color=(0, 0, 255), thickness=2\n",
    "    )\n",
    "\n",
    "    # 回転量を描画する。\n",
    "    cv2.ellipse(\n",
    "        img,\n",
    "        to_int_tuple(dst),\n",
    "        (20, 20),\n",
    "        angle=0,\n",
    "        startAngle=0,\n",
    "        endAngle=obj[\"angle\"],\n",
    "        color=(0, 0, 0),\n",
    "        thickness=-1,\n",
    "    )\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb2a935",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_objs[\"angle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb92050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b150f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef3aaab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab74fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2132a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# １枚目の画像を読み込む\n",
    "img1 =  cv2.imread(target_img_path)\n",
    "# ２枚目の画像を読み込む\n",
    "img2 = cv2.imread(\"C:/Users/a00m0/OneDrive/Nishimask/images/0099.jpg\") \n",
    "img1 = cv2.resize(img1, IMG_SIZE)\n",
    "img2 = cv2.resize(img2, IMG_SIZE)\n",
    "#img2_resized\n",
    "#img1_cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29d0742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A-KAZE検出器の生成\n",
    "akaze = cv2.AKAZE_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e12de5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像を読込、特徴量を計算\n",
    "# kp=keypoints(特徴点抽出), des=descriptors(特徴点描画)\n",
    "# detectAndCompute() => (kp:特徴点の一覧, des:各特徴点の特徴量記述子)  のタプルになります。\n",
    "kp1, des1 = akaze.detectAndCompute(img1, None)\n",
    "kp2, des2 = akaze.detectAndCompute(img2, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeccfd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量のマッチングを実行\n",
    "bf = cv2.BFMatcher() # 総当たりマッチング(Brute-Force Matcher)生成\n",
    "# 特徴量ベクトル同士をBrute-ForceとKNN(kth-nearest neighbor)でマッチング\n",
    "matches = bf.knnMatch(des1, des2, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff37666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データをマッチング精度の高いもののみ抽出\n",
    "ratio = 1\n",
    "good = []\n",
    "for m, n in matches:\n",
    "    if m.distance < ratio * n.distance:\n",
    "        good.append([m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdb0c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 対応する特徴点同士を描画\n",
    "img3 = cv2.drawMatchesKnn(img1_cropped, kp1, img2_resized, kp2, good, None, flags=2)\n",
    "\n",
    "# 画像表示\n",
    "cv2.imshow('img', img3)\n",
    "\n",
    "# キー押下で終了\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca5354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    " \n",
    "# 画像表示\n",
    "def imshow(img):\n",
    "    cv2.namedWindow(\"Result\", cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('Result', img) \n",
    "    cv2.waitKey(0) \n",
    "    cv2.destroyAllWindows()\n",
    " \n",
    "# img1の読み出し\n",
    "img1 = cv2.imread(\"C:/Users/a00m0/OneDrive/Nishimask/images/0099.jpg\") \n",
    "# img1をグレースケールで読み出し\n",
    "gray1 = cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY) \n",
    " \n",
    "akaze = cv2.AKAZE_create()\n",
    "kp1, des1 = akaze.detectAndCompute(gray1, None)\n",
    " \n",
    "img_akaze = cv2.drawKeypoints(img1, kp1, img1, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imwrite('match.png', img_akaze)\n",
    "imshow(img_akaze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8324c13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# １枚目の画像を読み込む\n",
    "img1 =  cv2.imread(target_img_path)\n",
    "# ２枚目の画像を読み込む\n",
    "img2 = cv2.imread(\"C:/Users/a00m0/OneDrive/Nishimask/images/0099.jpg\") \n",
    "img1 = cv2.resize(img1, IMG_SIZE)\n",
    "img2 = cv2.resize(img2, IMG_SIZE)\n",
    "\n",
    "# OBR 特徴量検出器を作成する。\n",
    "#detector = cv2.ORB_create()\n",
    "detector = cv2.AKAZE_create()\n",
    "# 特徴点を検出する。\n",
    "kp1, desc1 = detector.detectAndCompute(img1, None)\n",
    "kp2, desc2 = detector.detectAndCompute(img2, None)\n",
    "\n",
    "# マッチング器を作成する。\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "\n",
    "# マッチングを行う。\n",
    "matches = bf.knnMatch(desc1, desc2, k=2)\n",
    "\n",
    "# レシオテストを行う。\n",
    "good_matches = []\n",
    "thresh = 0.6\n",
    "for first, second in matches:\n",
    "    if first.distance < second.distance * thresh:\n",
    "        good_matches.append(first)\n",
    "        \n",
    "# マッチング結果を描画する。\n",
    "dst = cv2.drawMatches(img1, kp1, img2, kp2, good_matches, None)\n",
    "imshow(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7a161f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84863d02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c9dd20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron",
   "language": "python",
   "name": "detectron"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
